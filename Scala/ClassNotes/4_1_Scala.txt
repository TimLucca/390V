Akka
- a set of open-source libraries for desiging scalable, resilient systems that span processor cores and networks
    - so, can scale not only on processors but across and entire data center
- to be successful, distributed systems must cope in an enviornment where components crash without responding, messages get lost without a trace on the wire, and networks latency fluctuates
    - Netflix uses chaos monkey to "cause chaos" on its network in order to test its resilience
- multi-threaded behavior without the use of low-level concurrency constructs like atomics or locks
- is built from the ground up as a message passing system, so no resource sharing 
- transparent communication between systems and their components 
- a clustered, high-availability architecture that is elastic, scales in or out, on demand

Terminology
- uses the actor model
    - provides a level of abstraction
    - easier to write correct concurrent systems 
- concurrency means two or more tasks can be executed at the same time, although they do not have to be 
    - in contrast, parallelism is actually running two or more at the same time 
- blocking is the possible indefinite delay of one thread by another thread 
    - non-blocking means no thread can indefinitely delay another 
- deadlock is when no participants can make progress 
- starvation happens when there are participants that can make progress, but there might be one or more that cannot 
- a race condition is when an assumption about the ordering of a set of events might be violated by external non-deterministic effects 
- race conditions noften arise when multiple threads have a shared mutable state, and the operations of thread on the state might be interleaved causing unexpected behavior 

Concurrency
- requires synchronization of access to shared data
- mutual exclusion (mutexs) solve this problem 
    - 1 thread / 1 process has exclusive access to this piece of shared data 
    - uses locks and those locks must be atomic (it will run to completion)

What's Wrong with Locks 
- locks limit concurrency 
- they are very costly on modern CPU architectures 
- threads become blocked 
- easy to deadlock
- work best on single CPU 

Visibility
- CPUs don't talk to main memory, they talk to caches (with the exception of things like swap or test/set [locks])
- writes to one core are not visible to other cores
- must deal with cache coherence to run concurrently on multiple cores 
- its a major challenge to deal with visibility from a programmer's point of view 

Call Stacks
- explicitly spawning and managing threads difficult 
    - have to track their progress 
    - what to do when exception occurs?
        - they have their own call stack 
        - ex: when a thread throws a 'divide by 0 exception'
            - the exception is still thrown, however no thread is reported to by default 

Actors
- the actor model was proposed decads ago by Carl Hewitt as a way to handle parallel processing in a high performance network 
- allow us to enforce encapsulation without resorting to locks
    - the OO of parallelism 
- also allow us to use the model of cooperative enteties reacting to singals, changing state, and sending signals to eachother 
    - actors themselves are not multithreaded or concurrent
    - we allow the system to decide how the messages are sent instead of programming the parallelism 
- instead of calling methods, actors send messages to eachother 
- sending a message does not transfer the thread of execution from the sender to the destination 
- an actor can send a message and continue without blocking 
- react to incoming message sequentially, one at a time 
- actors have 
    - a mailbox 
    - behaviors 
    - messages 

Errors
- if an actor encounters an error in a message, it can send a message back 
- if an actor has an internal error, parent is notified 
    - actors form trees 
    - parent has control of what happens 
        - default is a new child is made and the same message is resent 
        - other decisions may be defined 

Control 
- whenever an actor is stopped, all of its childeren are recursively stooped too 
    - recursive termination 
    - seen in operating systems as cascading termination 
- on a failure, the default supervisor strategy is to stop and restart the child 


    ex of Echo Server

    import java.net._
    import java.io._
    improt akka.actor.{Actor, ActorRef, ActorSystem, Props}

    object Server {
        def props: Props = Prop[Server]         // the properties (initializer)
        final case class MySocket(socket: Socket)
    }

    class server extends Actor {
        import Server._                         // importing within the class

        def read_and_write(in: BufferedReader, out:BufferedWriter): Unit = {
            out.write(in.readLine())
            out.flush()
            in.close()
            out.close()
        }

        def recieve: PartialFunction[Any, Unit] = {
            case MySocket(s) =>
                val in = new BufferedReader(new InputStreamReader(s.getInputStream))
                val out = new BufferedWriter(new OutputStreamWriter(s.getOutputStream))
                
                read_and_write(in, out)
                
                s.close()
        }
    }

    object AkkaEchoServer {
        import Server._

        val system: ActorSystem = ActorSystem("AkkaEchoServer")
        val my_server: ActorRef = system.actorOf(Server.props)
    }